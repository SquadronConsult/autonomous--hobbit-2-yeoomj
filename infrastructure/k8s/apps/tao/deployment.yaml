apiVersion: apps/v1
kind: Deployment
metadata:
  name: tao-toolkit
  namespace: agricultural-system
  labels:
    app.kubernetes.io/name: tao-toolkit
    app.kubernetes.io/part-of: autonomous-agricultural-management
    app.kubernetes.io/version: "4.0.0"
    monitoring.agricultural-system.io/scrape: "true"
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app.kubernetes.io/name: tao-toolkit
  template:
    metadata:
      labels:
        app.kubernetes.io/name: tao-toolkit
        app.kubernetes.io/version: "4.0.0"
      annotations:
        checksum/config: ${CONFIG_CHECKSUM}
        prometheus.io/scrape: "true"
    spec:
      containers:
      - name: tao-toolkit
        image: nvcr.io/nvidia/tao:4.0.0
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "16Gi"
            cpu: "4"
          requests:
            nvidia.com/gpu: 1
            memory: "8Gi"
            cpu: "2"
        env:
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility,video"
        - name: PYTHONPATH
          value: "/app/src/backend/src"
        - name: MODEL_STORE_PATH
          value: "/app/models"
        - name: MAX_BATCH_SIZE
          value: "32"
        - name: INFERENCE_PRECISION
          value: "FP16"
        volumeMounts:
        - name: models
          mountPath: "/app/models"
          readOnly: true
        - name: tao-config
          mountPath: "/app/config"
          readOnly: true
        - name: encryption-keys
          mountPath: "/app/keys"
          readOnly: true
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        livenessProbe:
          exec:
            command:
            - python3
            - -c
            - "import torch; print(torch.cuda.is_available())"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 10
        startupProbe:
          httpGet:
            path: /startup
            port: 8080
          failureThreshold: 30
          periodSeconds: 10
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: tao-models-pvc
      - name: tao-config
        configMap:
          name: tao-config
      - name: encryption-keys
        secret:
          secretName: tao-secrets
      nodeSelector:
        nvidia.com/gpu: "true"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-Jetson-Orin
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault